{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import fastai\n",
    "import fastai.data.transforms as fastai_transforms\n",
    "import fastai.vision.data as vis_data\n",
    "import fastai.vision.augment as vis_augment\n",
    "import fastai.vision.learner as vis_learner\n",
    "import fastai.data.external as external_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n",
      "bn1\n",
      "relu\n",
      "maxpool\n",
      "layer1\n",
      "layer2\n",
      "layer3\n",
      "layer4\n",
      "avgpool\n",
      "fc\n"
     ]
    }
   ],
   "source": [
    "# Pretrained resnet model\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "resnet.eval()\n",
    "\n",
    "# Let's view the names of the children\n",
    "for name, _ in resnet.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: resnet does the same thing as\n",
    "# a sequential model built from its children\n",
    "#\n",
    "# We have to manually insert a flatten layer just before\n",
    "# the last child, as this operation is hard-coded in the\n",
    "# class torchvision.models.resnet.ResNet\n",
    "resnet_children = list(resnet.children())\n",
    "resnet_children.insert(-1, nn.Flatten(1))\n",
    "sequential_from_resnet_children = nn.Sequential(*resnet_children)\n",
    "\n",
    "# Verify the models have the same output\n",
    "X = torch.randn(100, 3, 224, 224)  # Random input data\n",
    "out_1 = resnet(X)\n",
    "out_2 = sequential_from_resnet_children(X)\n",
    "assert torch.equal(out_1, out_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fastai vision learner. This code is taken from\n",
    "# chapter 5 of the fastai book.\n",
    "path = external_data.untar_data(external_data.URLs.PETS)\n",
    "\n",
    "pets = vis_data.DataBlock(\n",
    "    blocks=(vis_data.ImageBlock, vis_data.CategoryBlock),\n",
    "    get_items=fastai_transforms.get_image_files,\n",
    "    splitter=fastai_transforms.RandomSplitter(seed=42),\n",
    "    get_y=vis_data.using_attr(\n",
    "        fastai_transforms.RegexLabeller(r\"(.+)_\\d+.jpg$\"), \"name\"\n",
    "    ),\n",
    "    item_tfms=vis_augment.Resize(460),\n",
    "    batch_tfms=vis_augment.aug_transforms(size=224, min_scale=0.75),\n",
    ")\n",
    "dls = pets.dataloaders(path / \"images\")\n",
    "\n",
    "learn = vis_learner.vision_learner(\n",
    "    dls, models.resnet18, metrics=fastai.metrics.error_rate\n",
    ")\n",
    "fastai_model = learn.model\n",
    "\n",
    "# The vision model created by fastai is a sequential model\n",
    "# with two steps.\n",
    "assert isinstance(fastai_model, nn.Sequential)\n",
    "assert len(fastai_model) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 0 of the fastai model is resnet with\n",
    "# the last two layers removed. We can verify this\n",
    "# by plugging in our random input into layer 0 of\n",
    "# the fastai model, and into all but the last two\n",
    "# layers of resnet, and seeing that the results are\n",
    "# equal.\n",
    "resnet_children = list(resnet.children())\n",
    "resnet_w_last_2_layers_removed = nn.Sequential(*resnet_children[:-2])\n",
    "out_1 = fastai_model[0](X)\n",
    "out_2 = resnet_w_last_2_layers_removed(X)\n",
    "assert torch.equal(out_1, out_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AdaptiveAvgPool2d(output_size=(1, 1)), Linear(in_features=512, out_features=1000, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "# The layers removed from the end of resnet are a\n",
    "# pooling layer and a linear layer.\n",
    "print(resnet_children[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): AdaptiveConcatPool2d(\n",
      "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
      "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
      "  )\n",
      "  (1): fastai.layers.Flatten(full=False)\n",
      "  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Dropout(p=0.25, inplace=False)\n",
      "  (4): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (5): ReLU(inplace=True)\n",
      "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): Dropout(p=0.5, inplace=False)\n",
      "  (8): Linear(in_features=512, out_features=37, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Layer 1 of the fastai model is something new that has\n",
    "# been added to resnet. It is a little more complex than\n",
    "# the pooling and linear layers that were removed.\n",
    "print(fastai_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight False\n",
      "1.weight True\n",
      "1.bias True\n",
      "4.0.conv1.weight False\n",
      "4.0.bn1.weight True\n",
      "4.0.bn1.bias True\n",
      "4.0.conv2.weight False\n",
      "4.0.bn2.weight True\n",
      "4.0.bn2.bias True\n",
      "4.1.conv1.weight False\n",
      "4.1.bn1.weight True\n",
      "4.1.bn1.bias True\n",
      "4.1.conv2.weight False\n",
      "4.1.bn2.weight True\n",
      "4.1.bn2.bias True\n",
      "5.0.conv1.weight False\n",
      "5.0.bn1.weight True\n",
      "5.0.bn1.bias True\n",
      "5.0.conv2.weight False\n",
      "5.0.bn2.weight True\n",
      "5.0.bn2.bias True\n",
      "5.0.downsample.0.weight False\n",
      "5.0.downsample.1.weight True\n",
      "5.0.downsample.1.bias True\n",
      "5.1.conv1.weight False\n",
      "5.1.bn1.weight True\n",
      "5.1.bn1.bias True\n",
      "5.1.conv2.weight False\n",
      "5.1.bn2.weight True\n",
      "5.1.bn2.bias True\n",
      "6.0.conv1.weight False\n",
      "6.0.bn1.weight True\n",
      "6.0.bn1.bias True\n",
      "6.0.conv2.weight False\n",
      "6.0.bn2.weight True\n",
      "6.0.bn2.bias True\n",
      "6.0.downsample.0.weight False\n",
      "6.0.downsample.1.weight True\n",
      "6.0.downsample.1.bias True\n",
      "6.1.conv1.weight False\n",
      "6.1.bn1.weight True\n",
      "6.1.bn1.bias True\n",
      "6.1.conv2.weight False\n",
      "6.1.bn2.weight True\n",
      "6.1.bn2.bias True\n",
      "7.0.conv1.weight False\n",
      "7.0.bn1.weight True\n",
      "7.0.bn1.bias True\n",
      "7.0.conv2.weight False\n",
      "7.0.bn2.weight True\n",
      "7.0.bn2.bias True\n",
      "7.0.downsample.0.weight False\n",
      "7.0.downsample.1.weight True\n",
      "7.0.downsample.1.bias True\n",
      "7.1.conv1.weight False\n",
      "7.1.bn1.weight True\n",
      "7.1.bn1.bias True\n",
      "7.1.conv2.weight False\n",
      "7.1.bn2.weight True\n",
      "7.1.bn2.bias True\n"
     ]
    }
   ],
   "source": [
    "# Fastai model is frozen by default, which is indicated by\n",
    "# frozen_idx = 2.\n",
    "#\n",
    "# All parameters in layer 1 (the new layer) have requires_grad=True\n",
    "# In layer 0, which comes from resnet, requires_grad is True for\n",
    "# some parameters, False for others.\n",
    "# Only parameters with requires_grad=True will be updated\n",
    "# during training.\n",
    "assert learn.opt.frozen_idx == 2\n",
    "assert all(param.requires_grad for param in fastai_model[1].parameters())\n",
    "\n",
    "for name, param in fastai_model[0].named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child 0: Conv2d\n",
      "  weight: False\n",
      "Child 1: BatchNorm2d\n",
      "  weight: True\n",
      "  bias: True\n",
      "Child 2: ReLU\n",
      "Child 3: MaxPool2d\n",
      "Child 4: Sequential\n",
      "  Child 0: BasicBlock\n",
      "    Child conv1: Conv2d\n",
      "      weight: False\n",
      "    Child bn1: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child relu: ReLU\n",
      "    Child conv2: Conv2d\n",
      "      weight: False\n",
      "    Child bn2: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "  Child 1: BasicBlock\n",
      "    Child conv1: Conv2d\n",
      "      weight: False\n",
      "    Child bn1: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child relu: ReLU\n",
      "    Child conv2: Conv2d\n",
      "      weight: False\n",
      "    Child bn2: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "Child 5: Sequential\n",
      "  Child 0: BasicBlock\n",
      "    Child conv1: Conv2d\n",
      "      weight: False\n",
      "    Child bn1: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child relu: ReLU\n",
      "    Child conv2: Conv2d\n",
      "      weight: False\n",
      "    Child bn2: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child downsample: Sequential\n",
      "      Child 0: Conv2d\n",
      "        weight: False\n",
      "      Child 1: BatchNorm2d\n",
      "        weight: True\n",
      "        bias: True\n",
      "  Child 1: BasicBlock\n",
      "    Child conv1: Conv2d\n",
      "      weight: False\n",
      "    Child bn1: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child relu: ReLU\n",
      "    Child conv2: Conv2d\n",
      "      weight: False\n",
      "    Child bn2: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "Child 6: Sequential\n",
      "  Child 0: BasicBlock\n",
      "    Child conv1: Conv2d\n",
      "      weight: False\n",
      "    Child bn1: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child relu: ReLU\n",
      "    Child conv2: Conv2d\n",
      "      weight: False\n",
      "    Child bn2: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child downsample: Sequential\n",
      "      Child 0: Conv2d\n",
      "        weight: False\n",
      "      Child 1: BatchNorm2d\n",
      "        weight: True\n",
      "        bias: True\n",
      "  Child 1: BasicBlock\n",
      "    Child conv1: Conv2d\n",
      "      weight: False\n",
      "    Child bn1: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child relu: ReLU\n",
      "    Child conv2: Conv2d\n",
      "      weight: False\n",
      "    Child bn2: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "Child 7: Sequential\n",
      "  Child 0: BasicBlock\n",
      "    Child conv1: Conv2d\n",
      "      weight: False\n",
      "    Child bn1: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child relu: ReLU\n",
      "    Child conv2: Conv2d\n",
      "      weight: False\n",
      "    Child bn2: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child downsample: Sequential\n",
      "      Child 0: Conv2d\n",
      "        weight: False\n",
      "      Child 1: BatchNorm2d\n",
      "        weight: True\n",
      "        bias: True\n",
      "  Child 1: BasicBlock\n",
      "    Child conv1: Conv2d\n",
      "      weight: False\n",
      "    Child bn1: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n",
      "    Child relu: ReLU\n",
      "    Child conv2: Conv2d\n",
      "      weight: False\n",
      "    Child bn2: BatchNorm2d\n",
      "      weight: True\n",
      "      bias: True\n"
     ]
    }
   ],
   "source": [
    "# We can examine more closely to see that\n",
    "# in layer 0 (coming from resnet), requires_grad\n",
    "# is only True for parameters in Norm layers, and\n",
    "# for bias parameters.\n",
    "def show_parameters(model, level=0):\n",
    "    \"\"\"\n",
    "    Recursively iterate through model's children, and show\n",
    "    requires_grad for each parameter\n",
    "    \"\"\"\n",
    "    align = level * \"  \"\n",
    "    for name, child in model.named_children():\n",
    "        print(f\"{align}Child {name}: {str(type(child)).split('.')[-1][:-2]}\")\n",
    "        if list(child.named_children()):\n",
    "            show_parameters(child, level + 1)\n",
    "        else:\n",
    "            for name, param in child.named_parameters():\n",
    "                print(f\"{align}  {name}: {param.requires_grad}\")\n",
    "\n",
    "\n",
    "show_parameters(fastai_model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-check that calling learn.freeze() doesn't change\n",
    "# the value of frozen_idx, since the model was frozen\n",
    "# to begin with.\n",
    "learn.freeze()\n",
    "assert learn.opt.frozen_idx == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the model is unfrozen, all parameters should have\n",
    "# requires_grad=True. We can see the model is unfrozen\n",
    "# because frozen_idx = 0.\n",
    "learn.unfreeze()\n",
    "assert learn.opt.frozen_idx == 0\n",
    "assert all(param.requires_grad for param in fastai_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
